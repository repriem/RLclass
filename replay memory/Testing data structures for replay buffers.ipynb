{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "- What we need for a good replay buffer: fixed-size, FIFO behavior, O(1) insertion at the end, O(1) sampling. Limited memory footprint.\n",
    "- [deque](https://docs.python.org/3/library/collections.html#collections.deque) has O(1) insertion time at the end, but O(n) access time (which made me doubt its ability to make a good replay buffer and try an np.array-based solution)\n",
    "- When we draw a mini-batch for DQN, it would be best to receive (separately) an array of states only, an array of actions, an array of rewards, an array of next states and a last array of \"done\", that we can pass these to the Q-network. What's the best way of doing that? Store them separately?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger\n",
    "import numpy as np\n",
    "logger.set_level(gym.logger.DISABLED)\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cartpole = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = cartpole.reset()\n",
    "action = cartpole.action_space.sample()\n",
    "next_state, reward, done, _ = cartpole.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer_size = int(1e6)\n",
    "nb_samples = int(2e6)\n",
    "nb_batches = int(1e4)\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def test_insertion_tqdm(buffer, nb_samples):\n",
    "    state = cartpole.reset()\n",
    "    for _ in trange(nb_samples):\n",
    "        buffer.append(state, action, reward, next_state, done)\n",
    "\n",
    "def test_sampling_tqdm(buffer, nb_batches):\n",
    "    for _ in trange(nb_batches):\n",
    "        buffer.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import gc\n",
    "\n",
    "def test_insertion_timeit(buffer, nb_samples):\n",
    "    print(\"Insertion of\", nb_samples, \"samples:\", \n",
    "      timeit.timeit('memory.append(state,action,reward,next_state,done)', \n",
    "                    globals=globals(), \n",
    "                    setup='gc.enable()', \n",
    "                    number=nb_samples))\n",
    "\n",
    "def test_sampling_timeit(buffer, nb_batches):\n",
    "    print(\"Sampling of\", nb_batches, \"batches:\",\n",
    "          timeit.timeit('memory.sample(batch_size)', \n",
    "                        globals=globals(), \n",
    "                        setup='gc.enable()', \n",
    "                        number=nb_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay buffer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n",
    "Transition = namedtuple('Transition', \n",
    "                        ('state', 'action', 'reward', 'next_state', 'done'))\n",
    "\n",
    "# But for the sake of the exercise, we will wrap this in a dedicated class.\n",
    "\n",
    "import random\n",
    "    \n",
    "class ReplayBuffer1(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    def append(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    def capacity(self):\n",
    "        return self.memory.maxlen\n",
    "    \n",
    "class ReplayBuffer2(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "    def capacity(self):\n",
    "        return self.memory.maxlen\n",
    "    \n",
    "class ReplayBuffer3(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self, batch_size)\n",
    "    \n",
    "class ReplayBuffer4(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append(Transition(state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self, batch_size)\n",
    "\n",
    "class ReplayBuffer5(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = np.empty(capacity, dtype=Transition)\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "        self.size = 0 # number of elements in the buffer\n",
    "        \n",
    "    def append(self, *args):\n",
    "        self.data[self.index] = Transition(*args)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "        if self.size < self.capacity:\n",
    "            self.size+=1\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        #indices = np.random.choice(self.size, size=batch_size, replace=False)\n",
    "        #return self.memory[indices]\n",
    "        return np.random.choice(self.data[:self.size], size=batch_size, replace=False)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "class ReplayBuffer6(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.data = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.data.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(np.array, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def capacity(self):\n",
    "        return self.data.maxlen\n",
    "\n",
    "class ReplayBuffer7(deque):\n",
    "    def __init__(self, capacity):\n",
    "        super().__init__(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        super().append(Transition(state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self, batch_size)\n",
    "        return list(map(np.array, list(zip(*batch))))\n",
    "    def capacity(self):\n",
    "        return self.maxlen\n",
    "    \n",
    "class ReplayBuffer8(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.data = deque(maxlen=capacity)\n",
    "    def append(self, state, action, reward, next_state, done):\n",
    "        self.data.append((state, action, reward, next_state, done))\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(torch.Tensor, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def capacity(self):\n",
    "        return self.data.maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer9:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "        \n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.data, batch_size)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "class ReplayBuffer10:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity # capacity of the buffer\n",
    "        self.data = []\n",
    "        self.index = 0 # index of the next cell to be filled\n",
    "    def append(self, s, a, r, s_, d):\n",
    "        if len(self.data) < self.capacity:\n",
    "            self.data.append(None)\n",
    "        self.data[self.index] = (s, a, r, s_, d)\n",
    "        self.index = (self.index + 1) % self.capacity\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.data, batch_size)\n",
    "        return list(map(torch.Tensor, list(zip(*batch))))\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo-unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([], maxlen=1000000)\n",
      "0\n",
      "deque([Transition(state=array([-0.01853433, -0.0036665 ,  0.00995653, -0.02980118]), action=1, reward=1.0, next_state=array([-0.01860766,  0.19131126,  0.00936051, -0.31932616]), done=False)], maxlen=1000000)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "memory = ReplayBuffer4(replay_buffer_size)\n",
    "print(memory)\n",
    "# len\n",
    "print(len(memory))\n",
    "# append\n",
    "memory.append(state, action, reward, next_state, done)\n",
    "print(memory)\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None None None ... None None None]\n",
      "0\n",
      "[Transition(state=array([-0.01853433, -0.0036665 ,  0.00995653, -0.02980118]), action=1, reward=1.0, next_state=array([-0.01860766,  0.19131126,  0.00936051, -0.31932616]), done=False)\n",
      " None None ... None None None]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# init\n",
    "memory = ReplayBuffer5(replay_buffer_size)\n",
    "print(memory.data)\n",
    "# len\n",
    "print(len(memory))\n",
    "# append\n",
    "memory.append(state, action, reward, next_state, done)\n",
    "print(memory.data)\n",
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:03<00:00, 566818.83it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 576.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.7041785359979258\n",
      "Sampling of 10000 batches: 16.558432882004126\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer1(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1350695.30it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 604.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.7784661740006413\n",
      "Sampling of 10000 batches: 15.611870838998584\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer2(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1171149.37it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 585.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.0343449819993111\n",
      "Sampling of 10000 batches: 16.888517145998776\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer3(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:03<00:00, 592494.36it/s]\n",
      "100%|██████████| 10000/10000 [00:17<00:00, 566.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 2.088889257000119\n",
      "Sampling of 10000 batches: 16.621598482997797\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer4(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:04<00:00, 405429.38it/s]\n",
      "100%|██████████| 10000/10000 [06:41<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 3.3488479379957425\n",
      "Sampling of 10000 batches: 463.5867436450062\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer5(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1171832.41it/s]\n",
      "100%|██████████| 10000/10000 [00:22<00:00, 452.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.8611387350101722\n",
      "Sampling of 10000 batches: 19.480439072998706\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer6(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:07<00:00, 277969.59it/s]\n",
      "100%|██████████| 10000/10000 [00:19<00:00, 502.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 2.130781361993286\n",
      "Sampling of 10000 batches: 16.827209620998474\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer7(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:01<00:00, 1386378.58it/s]\n",
      "100%|██████████| 10000/10000 [00:20<00:00, 477.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 0.7717193870048504\n",
      "Sampling of 10000 batches: 18.67609501199331\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer8(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:02<00:00, 844337.09it/s]\n",
      "100%|██████████| 10000/10000 [00:00<00:00, 18091.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.7328127619985025\n",
      "Sampling of 10000 batches: 0.6603696280071745\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer9(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000000/2000000 [00:02<00:00, 822408.11it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 3437.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insertion of 2000000 samples: 1.8442452210001647\n",
      "Sampling of 10000 batches: 2.8511063719925005\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayBuffer10(replay_buffer_size)\n",
    "test_insertion_tqdm(memory, nb_samples)\n",
    "test_sampling_tqdm(memory, nb_batches)\n",
    "test_insertion_timeit(memory, nb_samples)\n",
    "test_sampling_timeit(memory, nb_batches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
